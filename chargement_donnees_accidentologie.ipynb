{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4bb2a28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "#Importation des données\n",
    "from sqlalchemy import create_engine \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Etablir la connection entre python et mysql\n",
    "engine = create_engine(\"mysql+pymysql://hachem:tigertiger@localhost/ACCIDENT\")\n",
    "\n",
    "def chargement_vehicule(link, table):\n",
    "    \"\"\"\n",
    "    chargment des tables dans la base de donnée ACCIDENT\n",
    "    \"\"\"\n",
    "    print(\"Lecture des données\")\n",
    "    csize = 60000\n",
    "    #liste = ['Num_Acc','id_vehicule','num_veh','senc','catv','obs','obsm','choc','manv'\n",
    "    #         ,'motor']\n",
    "    liste = [\"Num_Acc\", \"Sens_de_circulation\" , \"Categorie_du_vehicule\" , \n",
    "            \"Nombre_occupants_TC\", \"Obstacle_fixe_heurte\", \"Obstacle_mobile_heurte\", \n",
    "            \"Choc\" , \"Maneuvre_avant_acc\", \"Num_Veh\"]\n",
    "    df = pd.read_csv(link, sep= ';', chunksize = csize,  skiprows = 1 \n",
    "                     , header = None, encoding='latin-1', names = liste)\n",
    "    print(\"Données lu\")\n",
    "    i = csize\n",
    "    for chunk in df:\n",
    "        chunk.to_sql(table, con = engine, if_exists='append', index = False)\n",
    "        i += csize\n",
    "        print(i)\n",
    "    return print(\"fin\")\n",
    "\n",
    "chargement_vehicule(\"donneebrute/vehicules_2020.csv\", \"VEHICULES_2020\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2019.csv\", \"VEHICULES_2019\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2018.csv\", \"VEHICULES_2018\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2017.csv\", \"VEHICULES_2017\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2016.csv\", \"VEHICULES_2016\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2015.csv\", \"VEHICULES_2015\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2014.csv\", \"VEHICULES_2014\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2013.csv\", \"VEHICULES_2013\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2012.csv\", \"VEHICULES_2012\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2011.csv\", \"VEHICULES_2011\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2010.csv\", \"VEHICULES_2010\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2009.csv\", \"VEHICULES_2009\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2008.csv\", \"VEHICULES_2008\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2007.csv\", \"VEHICULES_2007\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2006.csv\", \"VEHICULES_2006\")\n",
    "chargement_vehicule(\"donneebrute/vehicules_2005.csv\", \"VEHICULES_2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b36610b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "# Etablir la connection entre python et mysql\n",
    "from sqlalchemy import create_engine \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://hachem:tigertiger@localhost/ACCIDENT\")\n",
    "\n",
    "def chargement_usager(link, table):\n",
    "    \"\"\"\n",
    "    chargment des tables dans la base de donnée ACCIDENT\n",
    "    \"\"\"\n",
    "    print(\"Lecture des données\")\n",
    "    csize = 60000\n",
    "    liste = [\"Num_Acc\", \"place\", \"Categorie\", \"Grav\", \"Sexe\", \"Trajet\", \"Secu\", \"Localisation_du_pieton\", \"Action_du_pieton\", \"Etat_pieton\", \"Annee_naissance\" , \"Num_Veh\"]\n",
    "    df = pd.read_csv(link, sep= ',', chunksize = csize,  skiprows = 1 , header = None, encoding='latin-1', names = liste)\n",
    "    print(\"Données lu\")\n",
    "    i = csize\n",
    "    for chunk in df:\n",
    "        chunk.to_sql(table, con = engine, if_exists='append', index = False)\n",
    "        i += csize\n",
    "        print(i)\n",
    "    return print(\"fin\")\n",
    "\n",
    "#chargement_usager(\"donneebrute/usagers_2020.csv\", \"USAGERS_2020\")\n",
    "#chargement_usager(\"donneebrute/usagers_2019.csv\", \"USAGERS_2019\")\n",
    "chargement_usager(\"donneebrute/usagers_2018.csv\", \"USAGERS_2018\")\n",
    "chargement_usager(\"donneebrute/usagers_2017.csv\", \"USAGERS_2017\")\n",
    "chargement_usager(\"donneebrute/usagers_2016.csv\", \"USAGERS_2016\")\n",
    "chargement_usager(\"donneebrute/usagers_2015.csv\", \"USAGERS_2015\")\n",
    "chargement_usager(\"donneebrute/usagers_2014.csv\", \"USAGERS_2014\")\n",
    "chargement_usager(\"donneebrute/usagers_2013.csv\", \"USAGERS_2013\")\n",
    "chargement_usager(\"donneebrute/usagers_2012.csv\", \"USAGERS_2012\")\n",
    "chargement_usager(\"donneebrute/usagers_2011.csv\", \"USAGERS_2011\")\n",
    "chargement_usager(\"donneebrute/usagers_2010.csv\", \"USAGERS_2010\")\n",
    "chargement_usager(\"donneebrute/usagers_2009.csv\", \"USAGERS_2009\")\n",
    "chargement_usager(\"donneebrute/usagers_2008.csv\", \"USAGERS_2008\")\n",
    "chargement_usager(\"donneebrute/usagers_2007.csv\", \"USAGERS_2007\")\n",
    "chargement_usager(\"donneebrute/usagers_2006.csv\", \"USAGERS_2006\")\n",
    "chargement_usager(\"donneebrute/usagers_2005.csv\", \"USAGERS_2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e2d3e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des données\n",
      "Données lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/machinelearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "# Etablir la connection entre python et mysql\n",
    "engine = create_engine(\"mysql+pymysql://hachem:tigertiger@localhost/ACCIDENT\")\n",
    "\n",
    "\n",
    "def chargement_lieu(link, table):\n",
    "    \"\"\"\n",
    "    chargment des tables dans la base de donnée ACCIDENT\n",
    "    \"\"\"\n",
    "    print(\"Lecture des données\")\n",
    "    csize = 60000\n",
    "    liste = [\"Num_Acc\", \"Categorie_de_route\", \"Voie\", \"V1\", \"V2\", \"Regime_de_circulation\", \"Nombre_total_de_voies\", \"Numero_du_PR_de_rattachement\", \"Distance_en_metres_au_PR\", \"Vosp\", \"Profil\", \"Plan\", \"Largeur_du_terre_plein_central\", \"Larrout\", \"Surface\", \"Infrastructure\", \"Situation\", \"Point_ecole\"]\n",
    "    df = pd.read_csv(link,sep= ',', chunksize = csize,  skiprows = 1 , header = None, encoding='latin-1', names = liste)\n",
    "    print(\"Données lu\")\n",
    "    i = csize\n",
    "    for chunk in df:\n",
    "        chunk.to_sql(table, con = engine, if_exists='append', index = False)\n",
    "        i += csize\n",
    "        print(i)\n",
    "    return print(\"fin\")\n",
    "\n",
    "#chargement_lieu(\"donneebrute/lieux_2020.csv\", \"LIEUX_2020\")\n",
    "#chargement_lieu(\"donneebrute/lieux_2019.csv\", \"LIEUX_2019\")\n",
    "chargement_lieu(\"donneebrute/lieux_2018.csv\", \"LIEUX_2018\")\n",
    "chargement_lieu(\"donneebrute/lieux_2017.csv\", \"LIEUX_2017\")\n",
    "chargement_lieu(\"donneebrute/lieux_2016.csv\", \"LIEUX_2016\")\n",
    "chargement_lieu(\"donneebrute/lieux_2015.csv\", \"LIEUX_2015\")\n",
    "chargement_lieu(\"donneebrute/lieux_2014.csv\", \"LIEUX_2014\")\n",
    "chargement_lieu(\"donneebrute/lieux_2013.csv\", \"LIEUX_2013\")\n",
    "chargement_lieu(\"donneebrute/lieux_2012.csv\", \"LIEUX_2012\")\n",
    "chargement_lieu(\"donneebrute/lieux_2011.csv\", \"LIEUX_2011\")\n",
    "chargement_lieu(\"donneebrute/lieux_2010.csv\", \"LIEUX_2010\")\n",
    "chargement_lieu(\"donneebrute/lieux_2009.csv\", \"LIEUX_2009\")\n",
    "chargement_lieu(\"donneebrute/lieux_2008.csv\", \"LIEUX_2008\")\n",
    "chargement_lieu(\"donneebrute/lieux_2007.csv\", \"LIEUX_2007\")\n",
    "chargement_lieu(\"donneebrute/lieux_2006.csv\", \"LIEUX_2006\")\n",
    "chargement_lieu(\"donneebrute/lieux_2005.csv\", \"LIEUX_2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4742c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "## Etablir la connection entre python et mysql\n",
    "from sqlalchemy import create_engine \n",
    "import pandas as pd\n",
    "engine = create_engine(\"mysql+pymysql://hachem:tigertiger@localhost/ACCIDENT\")\n",
    "\n",
    "def chargement_caracteristique(link, table):\n",
    "    \"\"\"\n",
    "    chargment des tables dans la base de donnée ACCIDENT\n",
    "    \"\"\"\n",
    "    print(\"Lecture des données\")\n",
    "    csize = 60000\n",
    "    liste = [\"Num_Acc\", \"Annee\", \"Mois\", \"Jour\", \"heure_minute\", \"Lumiere\", \n",
    "             \"Localisation\", \"Intersection\", \"Conditions_atmospheriques\", \n",
    "             \"Type_de_collision\", \"Commune\", \"Adresse\", \"Gps\", \"Latitude\", \"Longitude\",\n",
    "             \"Departement\"]\n",
    "    df = pd.read_csv(link, chunksize = csize, skiprows = 1 , header = None\n",
    "                     , sep= ','\n",
    "                     ,  encoding='latin-1', names = liste)\n",
    "    print(\"Données lu\")\n",
    "    i = csize\n",
    "    for chunk in df:\n",
    "        chunk.to_sql(table, con = engine, if_exists='append', index = False)\n",
    "        i += csize\n",
    "        print(i)\n",
    "    return print(\"fin\")\n",
    "\n",
    "\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2020.csv\", \"CARACTERISTIQUE_2020\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2019.csv\", \"CARACTERISTIQUE_2019\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2018.csv\", \"CARACTERISTIQUE_2018\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2017.csv\", \"CARACTERISTIQUE_2017\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2016.csv\", \"CARACTERISTIQUE_2016\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2015.csv\", \"CARACTERISTIQUE_2015\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2014.csv\", \"CARACTERISTIQUE_2014\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2013.csv\", \"CARACTERISTIQUE_2013\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2012.csv\", \"CARACTERISTIQUE_2012\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2011.csv\", \"CARACTERISTIQUE_2011\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2010.csv\", \"CARACTERISTIQUE_2010\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2009.csv\", \"CARACTERISTIQUE_2009\")\n",
    "#chargement_caracteristique(\"donneebrute/caracteristiques_2008.csv\", \"CARACTERISTIQUE_2008\")\n",
    "chargement_caracteristique(\"donneebrute/caracteristiques_2007.csv\", \"CARACTERISTIQUE_2007\")\n",
    "chargement_caracteristique(\"donneebrute/caracteristiques_2006.csv\", \"CARACTERISTIQUE_2006\")\n",
    "chargement_caracteristique(\"donneebrute/caracteristiques_2005.csv\", \"CARACTERISTIQUE_2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7115f43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n",
      "Lecture des données\n",
      "Données lu\n",
      "120000\n",
      "180000\n",
      "240000\n",
      "300000\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine \n",
    "import pandas as pd\n",
    "engine = create_engine(\"mysql+pymysql://hachem:tigertiger@localhost/ACCIDENT\")\n",
    "def chargement_occupe(link, table):\n",
    "    \"\"\"\n",
    "    chargment des tables dans la base de donnée ACCIDENT\n",
    "    \"\"\"\n",
    "    print(\"Lecture des données\")\n",
    "    csize = 60000\n",
    "    liste = [\"Num_Acc_V\", \"Num_Acc_U\"]\n",
    "    df = pd.read_csv(link, chunksize = csize, skiprows = 1 , header = None\n",
    "                     , sep= ','\n",
    "                     #, sep = '\\t'\n",
    "                     ,  encoding='latin-1', names = liste)\n",
    "    print(\"Données lu\")\n",
    "    i = csize\n",
    "    for chunk in df:\n",
    "        chunk.to_sql(table, con = engine, if_exists='append', index = False)\n",
    "        i += csize\n",
    "        print(i)\n",
    "    return print(\"fin\")\n",
    "chargement_occupe('donneebrute/occupe_2017.csv', \"OCCUPE_2020\")\n",
    "chargement_occupe('donneebrute/occupe_2017.csv', \"OCCUPE_2019\")\n",
    "chargement_occupe('donneebrute/occupe_2017.csv', \"OCCUPE_2018\")\n",
    "chargement_occupe('donneebrute/occupe_2017.csv', \"OCCUPE_2017\")\n",
    "chargement_occupe('donneebrute/occupe_2016.csv', \"OCCUPE_2016\")\n",
    "chargement_occupe('donneebrute/occupe_2015.csv', \"OCCUPE_2015\")\n",
    "chargement_occupe('donneebrute/occupe_2014.csv', \"OCCUPE_2014\")\n",
    "chargement_occupe('donneebrute/occupe_2013.csv', \"OCCUPE_2013\")\n",
    "chargement_occupe('donneebrute/occupe_2012.csv', \"OCCUPE_2012\")\n",
    "chargement_occupe('donneebrute/occupe_2011.csv', \"OCCUPE_2011\")\n",
    "chargement_occupe('donneebrute/occupe_2010.csv', \"OCCUPE_2010\")\n",
    "chargement_occupe('donneebrute/occupe_2009.csv', \"OCCUPE_2009\")\n",
    "chargement_occupe('donneebrute/occupe_2008.csv', \"OCCUPE_2008\")\n",
    "chargement_occupe('donneebrute/occupe_2007.csv', \"OCCUPE_2007\")\n",
    "chargement_occupe('donneebrute/occupe_2006.csv', \"OCCUPE_2006\")\n",
    "chargement_occupe('donneebrute/occupe_2005.csv', \"OCCUPE_2005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb936395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201100000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148538</th>\n",
       "      <td>201100066973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148539</th>\n",
       "      <td>201100066973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148540</th>\n",
       "      <td>201100066974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148541</th>\n",
       "      <td>201100066974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148542</th>\n",
       "      <td>201100066974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148543 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Num_Acc_U\n",
       "0       201100000001\n",
       "1       201100000001\n",
       "2       201100000002\n",
       "3       201100000002\n",
       "4       201100000003\n",
       "...              ...\n",
       "148538  201100066973\n",
       "148539  201100066973\n",
       "148540  201100066974\n",
       "148541  201100066974\n",
       "148542  201100066974\n",
       "\n",
       "[148543 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "link1 = pd.read_csv('donneebrute/usagers_2011.csv', sep  = ',')\n",
    "link1 = link1.rename(columns= {'Num_Acc':'Num_Acc_U'})\n",
    "link1 = link1['Num_Acc_U']\n",
    "link1 = link1.to_frame()\n",
    "link1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13d00526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc_V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201100000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113849</th>\n",
       "      <td>201100066972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113850</th>\n",
       "      <td>201100066973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113851</th>\n",
       "      <td>201100066973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113852</th>\n",
       "      <td>201100066974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113853</th>\n",
       "      <td>201100066974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113854 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Num_Acc_V\n",
       "0       201100000001\n",
       "1       201100000001\n",
       "2       201100000002\n",
       "3       201100000002\n",
       "4       201100000003\n",
       "...              ...\n",
       "113849  201100066972\n",
       "113850  201100066973\n",
       "113851  201100066973\n",
       "113852  201100066974\n",
       "113853  201100066974\n",
       "\n",
       "[113854 rows x 1 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link2 = pd.read_csv('donneebrute/vehicules_2011.csv', sep = ',')\n",
    "link2 = link2.rename(columns= {'Num_Acc':'Num_Acc_V'})\n",
    "link2 = link2['Num_Acc_V']\n",
    "link2 = link2.to_frame()\n",
    "link2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67ed239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc_U</th>\n",
       "      <th>Num_Acc_V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201100000001</td>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201100000001</td>\n",
       "      <td>201100000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201100000002</td>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201100000002</td>\n",
       "      <td>201100000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201100000003</td>\n",
       "      <td>201100000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148538</th>\n",
       "      <td>201100066973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148539</th>\n",
       "      <td>201100066973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148540</th>\n",
       "      <td>201100066974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148541</th>\n",
       "      <td>201100066974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148542</th>\n",
       "      <td>201100066974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148543 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Num_Acc_U     Num_Acc_V\n",
       "0       201100000001  201100000001\n",
       "1       201100000001  201100000001\n",
       "2       201100000002  201100000002\n",
       "3       201100000002  201100000002\n",
       "4       201100000003  201100000003\n",
       "...              ...           ...\n",
       "148538  201100066973             0\n",
       "148539  201100066973             0\n",
       "148540  201100066974             0\n",
       "148541  201100066974             0\n",
       "148542  201100066974             0\n",
       "\n",
       "[148543 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = link1.merge( link2, how=\"outer\", left_index=True, right_index=True)\n",
    "link = link.fillna(0)\n",
    "link = link.astype(int)\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "58f3dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "link.to_csv('donneebrute/occupe_2011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d60df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
